# Анализ производительности Hadoop и Spark

## Архитектура
- **Hadoop Cluster**:
  - 1 NameNode
  - 1 или 3 DataNode (в зависимости от эксперимента)
  - HDFS для хранения данных
- **Spark Cluster**:
  - 1 Master
  - 1 Worker
  - Spark Application для анализа данных

## Технические характеристики
- **Датасет**: 150,000 записей о сотрудниках
  - Датасет генерируется автоматически при первом запуске
  - Генерация происходит через скрипт `generate_dataset.py`
  - Данные сохраняются в `employee_dataset.csv`
  - После генерации файл загружается в HDFS
- **Признаки**:
  - Категориальные: first_name, last_name, department
  - Числовые: employee_id, salary
  - Дата: hire_date
- **Размер блока HDFS**: 128MB
- **Ограничения памяти**: настраиваются через Docker

## Эксперименты
Проведено 4 эксперимента для сравнения производительности:

1. **1 DataNode без оптимизаций**
   - Базовая конфигурация
   - Время выполнения: 8.05 секунд
   - Использование памяти: ~0 MB

2. **1 DataNode с оптимизациями**
   - Оптимизированная конфигурация Spark
   - Время выполнения: 6.27 секунд
   - Использование памяти: 0.12 MB

3. **3 DataNode без оптимизаций**
   - Распределенная обработка
   - Время выполнения: 5.57 секунд
   - Использование памяти: ~0 MB

4. **3 DataNode с оптимизациями**
   - Распределенная обработка + оптимизации
   - Время выполнения: 6.11 секунд
   - Использование памяти: ~0 MB

## Оптимизации Spark
Применены следующие оптимизации:
```python
.config("spark.executor.memory", "1g")
.config("spark.driver.memory", "1g")
.config("spark.sql.shuffle.partitions", "10")
.config("spark.default.parallelism", "10")
.config("spark.storage.memoryFraction", "0.8")
.config("spark.memory.offHeap.enabled", "true")
.config("spark.memory.offHeap.size", "512m")
```

## Результаты анализа
1. **Влияние количества DataNodes**:
   - 3 DataNode показывают лучшую производительность
   - Уменьшение времени выполнения на ~30% по сравнению с 1 DataNode

2. **Эффективность оптимизаций**:
   - Оптимизации эффективны только для 1 DataNode
   - При 3 DataNode оптимизации могут немного снижать производительность

3. **Использование памяти**:
   - Все конфигурации показывают низкое использование памяти
   - Оптимизации незначительно увеличивают потребление памяти

## Визуализация
Файл с результатами (`experiment_results.png`) включен в репозиторий и доступен для просмотра. На графике представлены:
- Сравнение времени выполнения для всех конфигураций
- Сравнение использования памяти для всех конфигураций
- Визуальное представление эффективности оптимизаций

## Запуск проекта
1. Убедитесь, что установлен Docker и Docker Compose
2. Клонируйте репозиторий
3. Запустите контейнеры:
   ```bash
   docker-compose up -d
   ```
4. Дождитесь полного запуска всех сервисов
5. Запустите генерацию датасета и анализ:
   ```bash
   # Генерация датасета
   docker exec spark-submit python /app/generate_dataset.py
   
   # Запуск анализа
   docker exec spark-submit python /app/spark_app.py
   ```

## Структура проекта
```
.
├── docker-compose.yml          # Конфигурация Docker контейнеров
├── generate_dataset.py         # Скрипт генерации датасета
├── spark_app.py               # Spark приложение для анализа
├── requirements.txt           # Зависимости Python
├── .gitignore                 # Игнорируемые файлы Git
├── README.md                  # Документация проекта
└── experiment_results.png     # Визуализация результатов экспериментов
```

## Заключение
Проект демонстрирует важность правильной конфигурации распределенной системы. Основные выводы:
1. Увеличение количества DataNodes значительно улучшает производительность
2. Оптимизации Spark эффективны только в определенных конфигурациях
3. Распределенная обработка данных требует тщательной настройки параметров

